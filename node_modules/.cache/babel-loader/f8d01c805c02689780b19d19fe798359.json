{"ast":null,"code":"// import React, { Component } from \"react\";\n//\n// import { ReactMic } from 'react-mic';\n//\n// export class Example extends React.Component {\n//   constructor(props) {\n//     super(props);\n//     this.state = {\n//       record: false\n//     }\n//\n//   }\n// \n//   startRecording = () => {\n//     this.setState({\n//       record: true\n//     });\n//   }\n//\n//   stopRecording = () => {\n//     this.setState({\n//       record: false\n//     });\n//   }\n//\n//   onData(recordedBlob) {\n//     console.log('chunk of real-time data is: ', recordedBlob);\n//   }\n//\n//   onStop(recordedBlob) {\n//     console.log('recordedBlob is: ', recordedBlob);\n//   }\n//\n//   render() {\n//     return (\n//       <div>\n//         <ReactMic\n//           record={this.state.record}\n//           className=\"sound-wave\"\n//           onStop={this.onStop}\n//           onData={this.onData}\n//           strokeColor=\"#000000\"\n//           backgroundColor=\"#FF4081\" />\n//         <button onTouchTap={this.startRecording} type=\"button\">Start</button>\n//         <button onTouchTap={this.stopRecording} type=\"button\">Stop</button>\n//       </div>\n//     );\n//   }\n// }\n//\n// export default Example\n//\n//\n//\n//\n// // import PropTypes from \"prop-types\";\n// // import SpeechRecognition from \"react-speech-recognition\";\n// //\n// // const propTypes = {\n// //   // Props injected by SpeechRecognition\n// //   transcript: PropTypes.string,\n// //   resetTranscript: PropTypes.func,\n// //   browserSupportsSpeechRecognition: PropTypes.bool\n// // };\n// //\n// // const Dictaphone = ({\n// //   transcript,\n// //   resetTranscript,\n// //   browserSupportsSpeechRecognition\n// // }) => {\n// //   if (!browserSupportsSpeechRecognition) {\n// //     return null;\n// //   }\n// //\n// //   return (\n// //     <div>\n// //       <button onClick={resetTranscript}>Reset</button>\n// //       <span>{transcript}</span>\n// //     </div>\n// //   );\n// // };\n// //\n// // Dictaphone.propTypes = propTypes;\n// //\n// // export default SpeechRecognition(Dictaphone);\n//\n//\n//\n//\n// // import React, { Component } from 'react';\n// //\n// // import PropTypes from \"prop-types\";\n// // import SpeechRecognition from \"react-speech-recognition\";\n// //\n// //\n// //\n// // class Speech extends Component {\n// //\n// //   const propTypes = {\n// //     // Props injected by SpeechRecognition\n// //     transcript: PropTypes.string,\n// //     resetTranscript: PropTypes.func,\n// //     browserSupportsSpeechRecognition: PropTypes.bool\n// //   };\n// //\n// //   const Dictaphone = ({\n// //     transcript,\n// //     resetTranscript,\n// //     browserSupportsSpeechRecognition\n// //   }) => {\n// //     if (!browserSupportsSpeechRecognition) {\n// //       return null;\n// //     }\n// //\n// //   render(){\n// //\n// //     return(\n// //       <div>\n// //         <h3>Welcome to the speech </h3>\n// //           <div>\n// //        <button onClick={resetTranscript}>Reset</button>\n// //        <span>{transcript}</span>\n// //      </div>\n// //       </div>\n// //     )\n// //   }\n// // }\n// //\n// // export default Speech","map":{"version":3,"sources":["/Users/joshparry/sei/projects/marketplace-app-MERN-stack/marketplace-react-frontend/src/components/speechRecog.jsx"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sourcesContent":["// import React, { Component } from \"react\";\n//\n// import { ReactMic } from 'react-mic';\n//\n// export class Example extends React.Component {\n//   constructor(props) {\n//     super(props);\n//     this.state = {\n//       record: false\n//     }\n//\n//   }\n// \n//   startRecording = () => {\n//     this.setState({\n//       record: true\n//     });\n//   }\n//\n//   stopRecording = () => {\n//     this.setState({\n//       record: false\n//     });\n//   }\n//\n//   onData(recordedBlob) {\n//     console.log('chunk of real-time data is: ', recordedBlob);\n//   }\n//\n//   onStop(recordedBlob) {\n//     console.log('recordedBlob is: ', recordedBlob);\n//   }\n//\n//   render() {\n//     return (\n//       <div>\n//         <ReactMic\n//           record={this.state.record}\n//           className=\"sound-wave\"\n//           onStop={this.onStop}\n//           onData={this.onData}\n//           strokeColor=\"#000000\"\n//           backgroundColor=\"#FF4081\" />\n//         <button onTouchTap={this.startRecording} type=\"button\">Start</button>\n//         <button onTouchTap={this.stopRecording} type=\"button\">Stop</button>\n//       </div>\n//     );\n//   }\n// }\n//\n// export default Example\n//\n//\n//\n//\n// // import PropTypes from \"prop-types\";\n// // import SpeechRecognition from \"react-speech-recognition\";\n// //\n// // const propTypes = {\n// //   // Props injected by SpeechRecognition\n// //   transcript: PropTypes.string,\n// //   resetTranscript: PropTypes.func,\n// //   browserSupportsSpeechRecognition: PropTypes.bool\n// // };\n// //\n// // const Dictaphone = ({\n// //   transcript,\n// //   resetTranscript,\n// //   browserSupportsSpeechRecognition\n// // }) => {\n// //   if (!browserSupportsSpeechRecognition) {\n// //     return null;\n// //   }\n// //\n// //   return (\n// //     <div>\n// //       <button onClick={resetTranscript}>Reset</button>\n// //       <span>{transcript}</span>\n// //     </div>\n// //   );\n// // };\n// //\n// // Dictaphone.propTypes = propTypes;\n// //\n// // export default SpeechRecognition(Dictaphone);\n//\n//\n//\n//\n// // import React, { Component } from 'react';\n// //\n// // import PropTypes from \"prop-types\";\n// // import SpeechRecognition from \"react-speech-recognition\";\n// //\n// //\n// //\n// // class Speech extends Component {\n// //\n// //   const propTypes = {\n// //     // Props injected by SpeechRecognition\n// //     transcript: PropTypes.string,\n// //     resetTranscript: PropTypes.func,\n// //     browserSupportsSpeechRecognition: PropTypes.bool\n// //   };\n// //\n// //   const Dictaphone = ({\n// //     transcript,\n// //     resetTranscript,\n// //     browserSupportsSpeechRecognition\n// //   }) => {\n// //     if (!browserSupportsSpeechRecognition) {\n// //       return null;\n// //     }\n// //\n// //   render(){\n// //\n// //     return(\n// //       <div>\n// //         <h3>Welcome to the speech </h3>\n// //           <div>\n// //        <button onClick={resetTranscript}>Reset</button>\n// //        <span>{transcript}</span>\n// //      </div>\n// //       </div>\n// //     )\n// //   }\n// // }\n// //\n// // export default Speech\n"]},"metadata":{},"sourceType":"module"}